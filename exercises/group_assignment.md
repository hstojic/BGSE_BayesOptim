# Group projects

The main goal of the project is to get hands-on experience with the Bayesian optimization. You will work in groups of two, feel free to form these groups yourself. 

You can choose one of the following types of projects:  

1. Take some real world data and an algorithm that is relatively costly to evaluate and use Bayesian optimization to optimize the hyperparameters. Compare the Bayesian optimization systematically with grid search or any other algo for hyperparameter search.  
2. Rather than optimizing hyperparameters you can find a different application for Bayesian optimization (e.g. learning user preferences) and develop the code illustrating the application. Do your best to compare it to alternative approaches.  
3. Take a deeper dive into the method - e.g. compare different acquisition or function learning methods, different priors in finding a solution, different optimization routines etc. For this task you should use some of the benchmark functions where we know the solution (e.g. Brannin Hoo).  

The work does not need to be original, feel free to replicate a Bayesian optimization paper that you find interesting. I am fine with that, as long as you get some hands-on experience. Be careful with the underlying model that you will be optimizing and amount of data, no need to have a very costly problem that would take you a very long time to optimize.

To complete the assignment you should do the following:  

1. Write a brief report where you will present your findings. Report can be anything - a document, slides, webpage or a R/Jupyter notebook. No need to write too much, but do not put only the results - describe what you are doing and interpret the results.  
2. Code up the analysis. I should be able to redo the analysis ideally with a single line command. Analysis can be implemented in any language, though, I do have a preference for R and Python. I value well organized, readable code with some basic documentation. Feel free to use the existing Bayesian optimization libraries.  

Deadline is **June 20, 23:59**